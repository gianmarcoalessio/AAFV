{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import leggi_file_markdown,create_agent,Mediator,add_agents_to_mediator,send_and_print,validate_and_print\n",
    "from validator import ast_checker\n",
    "\n",
    "def is_java(test_category):\n",
    "    return \"java\" in test_category\n",
    "\n",
    "\n",
    "def is_js(test_category):\n",
    "    return \"javascript\" in test_category\n",
    "\n",
    "multiple ={\"id\": \"multiple_165\", \"question\": [[{\"role\": \"user\", \"content\": \"Find the price of a used Gibson Les Paul guitar in excellent condition in the Chicago area.\"}]], \"function\": [{\"name\": \"identify_color_rgb\", \"description\": \"This function identifies the RGB values of a named color.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"color_name\": {\"type\": \"string\", \"description\": \"Name of the color.\"}, \"standard\": {\"type\": \"string\", \"description\": \"The color standard (e.g. basic, pantone). Default is 'basic'\"}}, \"required\": [\"color_name\"]}}, {\"name\": \"board_game.chess.get_top_players\", \"description\": \"Find top chess players in a location based on rating.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city you want to find the players from.\"}, \"minimum_rating\": {\"type\": \"integer\", \"description\": \"Minimum rating to filter the players.\"}, \"number_of_players\": {\"type\": \"integer\", \"default\": 10, \"description\": \"Number of players you want to retrieve, default value is 10\"}}, \"required\": [\"location\", \"minimum_rating\"]}}, {\"name\": \"guitar_price.find\", \"description\": \"Retrieve the price of a specific used guitar model based on its condition and location.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"model\": {\"type\": \"string\", \"description\": \"The model of the guitar.\"}, \"condition\": {\"type\": \"string\", \"enum\": [\"Poor\", \"Good\", \"Excellent\"], \"description\": \"The condition of the guitar.\"}, \"location\": {\"type\": \"string\", \"description\": \"The location where the guitar is being sold.\"}}, \"required\": [\"model\", \"condition\", \"location\"]}}]}\n",
    "single = {\"id\": \"simple_321\", \"question\": [[{\"role\": \"user\", \"content\": \"What's the ranking of Barcelona in the 2021 La Liga season?\"}]], \"function\": [{\"name\": \"sports_ranking\", \"description\": \"Get the ranking of a team in a given sports league and season.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"team\": {\"type\": \"string\", \"description\": \"The name of the team.\"}, \"league\": {\"type\": \"string\", \"description\": \"The name of the sports league.\"}, \"season\": {\"type\": \"string\", \"description\": \"The season for which ranking needs to be obtained.\"}}, \"required\": [\"team\", \"league\", \"season\"]}}]}\n",
    "parallel = {\"id\": \"parallel_191\", \"question\": [[{\"role\": \"user\", \"content\": \"Can you help me find public libraries in New York, NY that have a Reading Room and Fiction section, and then in Los Angeles, CA that offer Wi-Fi and have a Children Section, and finally in Chicago, IL that have a Cafe and a Reading Room?\"}]], \"function\": [{\"name\": \"public_library.find_nearby\", \"description\": \"Locate nearby public libraries based on specific criteria like English fiction availability and Wi-Fi.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. Boston, MA\"}, \"facilities\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"enum\": [\"Wi-Fi\", \"Reading Room\", \"Fiction\", \"Children Section\", \"Cafe\"]}, \"description\": \"Facilities and sections in public library.\"}}, \"required\": [\"location\", \"facilities\"]}}]}\n",
    "parallel_multiple = {\"id\": \"parallel_multiple_174\", \"question\": [[{\"role\": \"user\", \"content\": \"\\\"Could you help me with a few tasks? First, I need to convert 5000 Euros to US dollars. After that, I would like to know the population of turtles in Galapagos Islands in the year 2018, and also include the species information. Then, I need to plan a trip from New York to Los Angeles, but I want to avoid tolls and ferries. Finally, I need to convert 3000 British Pounds to Japanese Yen.\\\"\"}]], \"function\": [{\"name\": \"convert_currency\", \"description\": \"Converts an amount from a particular currency to another currency.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"base_currency\": {\"type\": \"string\", \"description\": \"The base currency in which the original amount is present.\"}, \"target_currency\": {\"type\": \"string\", \"description\": \"The currency to which you want to convert.\"}, \"amount\": {\"type\": \"integer\", \"description\": \"The amount you want to convert.\"}}, \"required\": [\"base_currency\", \"target_currency\", \"amount\"]}}, {\"name\": \"map_service.get_directions\", \"description\": \"Retrieve directions from a starting location to an ending location, including options for route preferences.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"start\": {\"type\": \"string\", \"description\": \"Starting location for the route.\"}, \"end\": {\"type\": \"string\", \"description\": \"Ending location for the route.\"}, \"avoid\": {\"type\": \"array\", \"items\": {\"type\": \"string\", \"enum\": [\"tolls\", \"highways\", \"ferries\"]}, \"description\": \"Route features to avoid. Default is none if not specified.\"}}, \"required\": [\"start\", \"end\"]}}, {\"name\": \"ecology.get_turtle_population\", \"description\": \"Get the population and species of turtles in a specific location.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The name of the location.\"}, \"year\": {\"type\": \"integer\", \"description\": \"The year of the data requested. Default is 2023 if not specified.\"}, \"species\": {\"type\": \"boolean\", \"description\": \"Whether to include species information. Default is false. (optional)\"}}, \"required\": [\"location\"]}}]}\n",
    "java = {\"id\": \"java_72\", \"question\": [[{\"role\": \"user\", \"content\": \"Help me append a substring of characters from a character array `textBuffer` starting at index 5 with a length of 10 characters to a text stream while handling XML serialization?\"}]], \"function\": [{\"name\": \"ToTextStream.characters\", \"description\": \"Writes a range of characters from a character array to the text stream. It handles temporary and final output states differently, normalizing characters if necessary and tracing the event if a tracer is set.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"ch\": {\"type\": \"Array\", \"description\": \"The character array from which a range of characters will be written.\", \"items\": {\"type\": \"char\"}}, \"start\": {\"type\": \"integer\", \"description\": \"The start index in the character array from which to begin writing characters.\"}, \"length\": {\"type\": \"integer\", \"description\": \"The number of characters to write from the character array.\"}}, \"required\": [\"ch\", \"start\", \"length\"]}}]}\n",
    "javascript = {\"id\": \"javascript_18\", \"question\": [[{\"role\": \"user\", \"content\": \"What is the final velocity for an object in free fall after 5 seconds, given the gravity g and initial velocity 0?\"}]], \"function\": [{\"name\": \"calculateFinalVelocity\", \"description\": \"This function calculates the final velocity of an object in free fall after a certain time, taking into account the acceleration due to gravity and the initial velocity.\", \"parameters\": {\"type\": \"dict\", \"properties\": {\"time\": {\"type\": \"float\", \"description\": \"The time in seconds for which the object has been in free fall.\"}, \"gravity\": {\"type\": \"float\", \"description\": \"The acceleration due to gravity, typically in m/s^2.\"}, \"initialVelocity\": {\"type\": \"float\", \"description\": \"The initial velocity of the object in m/s at the start of the free fall.\"}}, \"required\": [\"time\", \"gravity\", \"initialVelocity\"]}}]}\n",
    "\n",
    "\n",
    "test_entry = multiple\n",
    "\"\"\"\n",
    "# Andare su `cd /home/ago/giammy/TESI-MAGISTRALE/models/llama.cpp`\n",
    "\n",
    "croswil/Llama_Llama-3.1-8B-Instruct \n",
    "croswil/Llama_Llama-3.2-3B-Instruct \n",
    "\n",
    "croswil/Qwen_Qwen2.5-1.5B-Instruct \n",
    "croswil/Qwen_Qwen2.5-3B-Instruct \n",
    "croswil/Qwen_Qwen2.5-7B-Instruct \n",
    "\n",
    "./llama-server \\\n",
    "  --hf-repo croswil/Qwen_Qwen2.5-1.5B-Instruct \\\n",
    "  --hf-file unsloth.Q4_K_M.gguf\n",
    "\n",
    "./llama-server \\\n",
    "  --hf-repo croswil/Qwen_Qwen2.5-3B-Instruct  \\\n",
    "  --hf-file unsloth.Q4_K_M.gguf\n",
    "\n",
    "./llama-server \\\n",
    "  --hf-repo croswil/Qwen_Qwen2.5-7B-Instruct  \\\n",
    "  --hf-file Qwen2.5-7B-Instruct-Q4_K_M.gguf\n",
    "\n",
    "./llama-server \\\n",
    "  --hf-repo croswil/Llama_Llama-3.2-3B-Instruct  \\\n",
    "  --hf-file llama-3.2-3b-instruct-q4_k_m.gguf\n",
    "\n",
    "./llama-server \\\n",
    "  --hf-repo croswil/Llama_Llama-3.1-8B-Instruct  \\\n",
    "  --hf-file Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "local_endpoint = \"http://localhost:8080/v1/chat/completions\"\n",
    "qwen_1_5b_endpoint = \"https://qczw73rk6noiiz27.us-east-1.aws.endpoints.huggingface.cloud/v1/chat/completions\" \n",
    "qwen_3b_endpoint = \"\"\n",
    "qwen_7b_endpoint = \"\"\n",
    "llama_3b_endpoint =\"\"\n",
    "llama_8b_endpoint =\"https://l41j2vkrxy8txnck.us-east-1.aws.endpoints.huggingface.cloud/v1/chat/completions\"\n",
    "huggingface_endpoint_url = local_endpoint\n",
    "\n",
    "huggingface_endpoint_url = ''\n",
    "\n",
    "# Configuration Constants\n",
    "MODEL_NAME_BFCL = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
    "# MODEL_NAME_BFCL = 'gpt-4o-mini'\n",
    "TEMPERATURE = 0.9\n",
    "MAX_TURNS = 4\n",
    "VALIDATION_CONDITION = \"Valid: The function call respects the parameter types and requirements.\"\n",
    "N_TESTS = 1\n",
    "TEST_CATEGORY = \"parallel\"\n",
    "language = \"Python\"\n",
    "\n",
    "if is_java(TEST_CATEGORY):\n",
    "    language = \"Java\"\n",
    "if is_js(TEST_CATEGORY):\n",
    "    language = \"JavaScript\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid': True, 'error': [], 'error_type': 'parallel_function_checker_no_order:partial_match'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res_caller='[guitar_price.find(model=\"Les Paul\", condition=\"Excellent\", location=\"Chicago\")]'\n",
    "validator_result = ast_checker(test_entry[\"function\"], res_caller, language, TEST_CATEGORY, MODEL_NAME_BFCL)\n",
    "print(validator_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_tester = leggi_file_markdown('system_prompt/tester.md',test_entry[\"function\"])\n",
    "system_prompt_caller = leggi_file_markdown('system_prompt/caller.md',test_entry[\"function\"])\n",
    "system_prompt_caller_feedback = leggi_file_markdown('system_prompt/caller_feedback.md',test_entry[\"function\"])\n",
    "system_prompt_validator = leggi_file_markdown('system_prompt/validator.md')\n",
    "system_prompt_validator_feedback = leggi_file_markdown('system_prompt/validator_feedback.md',test_entry[\"function\"])\n",
    "\n",
    "mediator = Mediator()\n",
    "# Create Agents\n",
    "tester = create_agent(\"assistant\", system_prompt_tester, MODEL_NAME_BFCL,temperature=1,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "caller = create_agent(\"assistant\", system_prompt_caller, MODEL_NAME_BFCL,temperature=TEMPERATURE, huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "caller_feedback = create_agent(\"assistant\", system_prompt_caller_feedback, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "validator = create_agent(\"assistant\", system_prompt_validator, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "validator_feedback = create_agent(\"assistant\", system_prompt_validator_feedback, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "\n",
    "add_agents_to_mediator(mediator, tester, caller,caller_feedback,validator,validator_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:                    Find the price of a used Gibson Les Paul guitar in excellent condition in the Chicago area.\n",
      "TESTER (Test 1):               Find the price of a used Gibson Les Paul guitar in excellent condition in the Chicago area.\n",
      "CALLER (Test 1):               [guitar_price.find(model=\"Les Paul\", condition=\"Excellent\", location=\"Chicago\")]\n",
      "{'valid': True, 'error': [], 'error_type': 'parallel_function_checker_no_order:partial_match'}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Tester Interaction\n",
    "user_question = test_entry[\"question\"][0][0]['content']\n",
    "print(f'USER:                    {user_question}')\n",
    "# Initialization\n",
    "previous_tests = []\n",
    "\n",
    "for idx in range(N_TESTS):\n",
    "\n",
    "    res_tester = send_and_print(mediator, \"user\", tester.id, user_question, f\"TESTER (Test {idx+1}):\")\n",
    "    res_caller = send_and_print(mediator, tester.id, caller.id, res_tester, f\"CALLER (Test {idx+1}):\")\n",
    "    \n",
    "    # Step 2: Validation\n",
    "    validator_result = ast_checker(test_entry[\"function\"], res_caller, language, TEST_CATEGORY, MODEL_NAME_BFCL)\n",
    "    \n",
    "    # Aggiungi il risultato del test alla lista dei test precedenti\n",
    "    previous_tests.append(validator_result)\n",
    "\n",
    "print(validator_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_TESTS):\n\u001b[0;32m----> 3\u001b[0m     res_tester \u001b[38;5;241m=\u001b[39m send_and_print(mediator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, tester\u001b[38;5;241m.\u001b[39mid, \u001b[43muser_question\u001b[49m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTESTER (Test \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     res_caller \u001b[38;5;241m=\u001b[39m send_and_print(mediator, tester\u001b[38;5;241m.\u001b[39mid, caller\u001b[38;5;241m.\u001b[39mid, res_tester, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALLER (Test \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Step 2: Validation\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_question' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx in range(N_TESTS):\n",
    "    \n",
    "    res_tester = send_and_print(mediator, \"user\", tester.id, user_question, f\"TESTER (Test {idx+1}):\")\n",
    "    res_caller = send_and_print(mediator, tester.id, caller.id, res_tester, f\"CALLER (Test {idx+1}):\")\n",
    "    \n",
    "    # Step 2: Validation\n",
    "    validator_result = validate_and_print(res_caller, test_entry[\"function\"], f\"VALIDATION (Test {idx+1}):\")\n",
    "    \n",
    "    # Raccogli i risultati in un dizionario\n",
    "    test_result = {\n",
    "        \"user_question\": user_question,\n",
    "        \"res_tester\": res_tester,\n",
    "        \"res_caller\": res_caller,\n",
    "        \"validator_result\": validator_result[\"validation_result\"]\n",
    "    }\n",
    "    \n",
    "    # Aggiungi il risultato del test alla lista dei test precedenti\n",
    "    previous_tests.append(test_result)\n",
    "\n",
    "content_feedback = f\"The Question that you have to reply is: {user_question} \\n\\n Below you can find the feedback for the previous tests: \\n\\n\"\n",
    "\n",
    "for idx, test in enumerate(previous_tests):\n",
    "\n",
    "    print(test)\n",
    "    content_feedback += f\"\"\"\n",
    "**Test {idx+1}:**\n",
    "**Tester Question**: {test['res_tester']}\n",
    "**Function Calling Response**: {test['res_caller']}\n",
    "**Validation Feedback Response**: {test['validator_result']}\n",
    "\"\"\"\n",
    "    \n",
    "print(content_feedback)\n",
    "\n",
    "res_caller_feedback = send_and_print(mediator, \"user\", caller_feedback.id, content_feedback, \"CALLER_FEEDBACK:\")\n",
    "validator_result = validate_and_print(res_caller_feedback, test_entry[\"function\"], \"VALIDATATION:\")\n",
    "\n",
    "caller_feedback_content = f\"\"\"\n",
    "**Question**: {user_question}\n",
    "**Function Calling Response**: {res_caller_feedback}\n",
    "**Validation Feedback**: {validator_result[\"validation_result\"]}\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Final Caller Agent and Iterative Chat\n",
    "\n",
    "print('--------------VALIDATOR-CHAT--------------')\n",
    "\n",
    "counter = 0\n",
    "res_recipient = caller_feedback_content\n",
    "\n",
    "while counter < MAX_TURNS:\n",
    "    res_recipient = send_and_print(mediator, validator.id, validator_feedback.id, res_recipient, f\"[{validator_feedback.name}]\")\n",
    "    \n",
    "    if VALIDATION_CONDITION in res_recipient:\n",
    "        break\n",
    "\n",
    "    validator_result = validate_and_print(res_recipient, test_entry[\"function\"], \"VALIDATOR:\")\n",
    "    \n",
    "    caller_feedback_content = f\"\"\"\n",
    "    **Question**: {user_question}\n",
    "    **Function Calling Response**: {res_recipient}\n",
    "    **Validation Feedback**: {validator_result[\"validation_result\"]}\n",
    "    \"\"\"\n",
    "    res_sender = send_and_print(mediator, validator_feedback.id, validator.id, caller_feedback_content, f\"[{validator.name}]\")\n",
    "    \n",
    "    if VALIDATION_CONDITION in res_sender:\n",
    "        break\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "print('------------------------------------------')\n",
    "print('VALIDATOR_FEEDBACK:', res_recipient)\n",
    "\n",
    "# Final Interaction Without Agent\n",
    "res_without_agent = send_and_print(mediator, \"user\", caller.id, user_question, \"CALLER(QUANTIZE):\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUND TESTING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to load model from file: /home/ago/giammy/TESI-MAGISTRALE/models/hugginface-models/Qwen2.5-1.5B-Instruct/unsloth.Q4_K_M.gguf",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m validator_feedback \u001b[38;5;241m=\u001b[39m create_agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator_feedback\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_prompt_validator_feedback, MODEL_NAME_BFCL,temperature\u001b[38;5;241m=\u001b[39mTEMPERATURE,huggingface_endpoint_url\u001b[38;5;241m=\u001b[39mhuggingface_endpoint_url)\n\u001b[1;32m     30\u001b[0m add_agents_to_mediator(mediator, tester, caller,caller_feedback,validator,validator_feedback)\n\u001b[0;32m---> 33\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent_architecture\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMODEL_NAME_BFCL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m      \u001b[49m\u001b[43murl_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhuggingface_endpoint_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtest_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbfcl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mn_tests\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TESTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mMAX_TURNS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_TURNS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mVALIDATION_CONDITION\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mValid: The function call respects the parameter types and requirements.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     42\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m result_entry \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTEST_CATEGORY\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\n\u001b[1;32m     47\u001b[0m }\n\u001b[1;32m     48\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result_entry)\n",
      "File \u001b[0;32m~/giammy/TESI-MAGISTRALE/thesis/berkeley-function-call-leaderboard/agent/agent_architecture.py:43\u001b[0m, in \u001b[0;36magent_architecture\u001b[0;34m(model_name, temperature, url_endpoint, test_entry, bfcl, n_tests, MAX_TURNS, VALIDATION_CONDITION)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Create Agents\u001b[39;00m\n\u001b[1;32m     42\u001b[0m tester \u001b[38;5;241m=\u001b[39m create_agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_prompt_tester, model_name,temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,huggingface_endpoint_url\u001b[38;5;241m=\u001b[39murl_endpoint)\n\u001b[0;32m---> 43\u001b[0m caller \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt_caller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_endpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m caller_feedback \u001b[38;5;241m=\u001b[39m create_agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_prompt_caller_feedback, model_name,temperature,url_endpoint)\n\u001b[1;32m     45\u001b[0m validator \u001b[38;5;241m=\u001b[39m create_agent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_prompt_validator, model_name,temperature,url_endpoint)\n",
      "File \u001b[0;32m~/giammy/TESI-MAGISTRALE/thesis/berkeley-function-call-leaderboard/utils.py:17\u001b[0m, in \u001b[0;36mcreate_agent\u001b[0;34m(name, system_instruction, model_name, temperature, huggingface_endpoint_url)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_agent\u001b[39m(name, system_instruction, model_name,temperature,huggingface_endpoint_url):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an OpenSourceAgent with the given parameters.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOpenSourceAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_instruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhuggingface_endpoint_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhuggingface_endpoint_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/giammy/TESI-MAGISTRALE/thesis/berkeley-function-call-leaderboard/agent/agent_framework.py:53\u001b[0m, in \u001b[0;36mOpenSourceAgent.__init__\u001b[0;34m(self, name, system_instruction, temperature, model_name, end_condition, tools, huggingface_endpoint_url)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in configuration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m huggingface_endpoint_url \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Load local model\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmy_model \u001b[38;5;241m=\u001b[39m \u001b[43mLlama\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# n_threads=8,\u001b[39;49;00m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# n_gpu_layers=35,\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_token_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|EOT|>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/BFCL-wtf/lib/python3.10/site-packages/llama_cpp/llama.py:369\u001b[0m, in \u001b[0;36mLlama.__init__\u001b[0;34m(self, model_path, n_gpu_layers, split_mode, main_gpu, tensor_split, rpc_servers, vocab_only, use_mmap, use_mlock, kv_overrides, seed, n_ctx, n_batch, n_ubatch, n_threads, n_threads_batch, rope_scaling_type, pooling_type, rope_freq_base, rope_freq_scale, yarn_ext_factor, yarn_attn_factor, yarn_beta_fast, yarn_beta_slow, yarn_orig_ctx, logits_all, embedding, offload_kqv, flash_attn, last_n_tokens_size, lora_base, lora_scale, lora_path, numa, chat_format, chat_handler, draft_model, tokenizer, type_k, type_v, spm_infill, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_path):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel path does not exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m    368\u001b[0m     contextlib\u001b[38;5;241m.\u001b[39mclosing(\n\u001b[0;32m--> 369\u001b[0m         \u001b[43minternals\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    375\u001b[0m )\n\u001b[1;32m    377\u001b[0m \u001b[38;5;66;03m# Override tokenizer\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_ \u001b[38;5;241m=\u001b[39m tokenizer \u001b[38;5;129;01mor\u001b[39;00m LlamaTokenizer(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/BFCL-wtf/lib/python3.10/site-packages/llama_cpp/_internals.py:56\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[0;34m(self, path_model, params, verbose)\u001b[0m\n\u001b[1;32m     51\u001b[0m     model \u001b[38;5;241m=\u001b[39m llama_cpp\u001b[38;5;241m.\u001b[39mllama_load_model_from_file(\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_model\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\n\u001b[1;32m     53\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load model from file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfree_model\u001b[39m():\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to load model from file: /home/ago/giammy/TESI-MAGISTRALE/models/hugginface-models/Qwen2.5-1.5B-Instruct/unsloth.Q4_K_M.gguf"
     ]
    }
   ],
   "source": [
    "from agent.agent_architecture import agent_architecture\n",
    "from utils_v001 import prepare_test_environment, write\n",
    "\n",
    "\n",
    "TEST_CATEGORY = \"simple\"\n",
    "offset = 0\n",
    "test_cases_total, handler = prepare_test_environment(MODEL_NAME_BFCL, TEMPERATURE, TEST_CATEGORY)\n",
    "test_cases_total = test_cases_total[offset:]\n",
    "\n",
    "# Lista per salvare i risultati\n",
    "results = []\n",
    "\n",
    "# Itera su tutti i test cases\n",
    "for i, test_entry in enumerate(test_cases_total):\n",
    "    global_index = i + offset\n",
    "\n",
    "    system_prompt_tester = leggi_file_markdown('system_prompt/tester.md')\n",
    "    system_prompt_caller = leggi_file_markdown('system_prompt/caller.md',test_entry[\"function\"])\n",
    "    system_prompt_caller_feedback = leggi_file_markdown('system_prompt/caller_feedback.md',test_entry[\"function\"])\n",
    "    system_prompt_validator = leggi_file_markdown('system_prompt/validator.md')\n",
    "    system_prompt_validator_feedback = leggi_file_markdown('system_prompt/validator_feedback.md',test_entry[\"function\"])\n",
    "\n",
    "    # Create Agents\n",
    "    tester = create_agent(\"tester\", system_prompt_tester, MODEL_NAME_BFCL,temperature=0.1,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "    caller = create_agent(\"caller\", system_prompt_caller, MODEL_NAME_BFCL,temperature=TEMPERATURE, huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "    caller_feedback = create_agent(\"caller_feedback\", system_prompt_caller_feedback, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "    validator = create_agent(\"validator\", system_prompt_validator, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "    validator_feedback = create_agent(\"validator_feedback\", system_prompt_validator_feedback, MODEL_NAME_BFCL,temperature=TEMPERATURE,huggingface_endpoint_url=huggingface_endpoint_url)\n",
    "\n",
    "    add_agents_to_mediator(mediator, tester, caller,caller_feedback,validator,validator_feedback)\n",
    "\n",
    "\n",
    "    result = agent_architecture(\n",
    "          model_name = MODEL_NAME_BFCL,\n",
    "          temperature=TEMPERATURE,\n",
    "          url_endpoint= huggingface_endpoint_url,\n",
    "          test_entry=test_entry,\n",
    "          bfcl=False,\n",
    "          n_tests=N_TESTS,\n",
    "          MAX_TURNS=MAX_TURNS,\n",
    "          VALIDATION_CONDITION=\"Valid: The function call respects the parameter types and requirements.\"\n",
    "    )\n",
    "\n",
    "    result_entry = {\n",
    "        \"id\": f\"{TEST_CATEGORY}_{global_index}\",\n",
    "        \"result\": result\n",
    "    }\n",
    "    results.append(result_entry)\n",
    "\n",
    "    write(result_entry, MODEL_NAME_BFCL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BFCL-wtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
